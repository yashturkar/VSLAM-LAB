import subprocess
import os, shutil
import pandas as pd
from tqdm import tqdm
from pathlib import Path

from Evaluate.evo_functions import evo_metric, evo_get_accuracy
from path_constants import VSLAM_LAB_EVALUATION_FOLDER, TRAJECTORY_FILE_NAME, GROUNTRUTH_FILE
from utilities import print_msg, ws, format_msg, read_trajectory_txt, save_trajectory_csv

SCRIPT_LABEL = f"\033[95m[{os.path.basename(__file__)}]\033[0m "

def evaluate_sequence(exp, dataset, sequence_name, overwrite=False):
    command =  "pixi run -e vslamlab evo_config set save_traj_in_zip true"
    subprocess.run(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)

    METRIC = 'ate'
    
    trajectories_path = os.path.join(exp.folder, dataset.dataset_folder, sequence_name)
    groundtruth_csv = Path(exp.folder) / dataset.dataset_folder / sequence_name /  GROUNTRUTH_FILE
    evaluation_folder = os.path.join(exp.folder, dataset.dataset_folder, sequence_name, VSLAM_LAB_EVALUATION_FOLDER)
    accuracy_csv = os.path.join(evaluation_folder, f'{METRIC}.csv')

    # Load experiments log
    exp_log = pd.read_csv(exp.log_csv)
    if overwrite:
        if os.path.exists(evaluation_folder):
            shutil.rmtree(evaluation_folder)        
        exp_log.loc[exp_log["sequence_name"] == sequence_name, "EVALUATION"] = "none"

    os.makedirs(evaluation_folder, exist_ok=True)

    # Find runs to evaluate
    # Also evaluate sequences with SUCCESS=False if they have trajectory files (may have been saved despite failure)
    runs_to_evaluate = []
    for _, row in exp_log.iterrows():
        if (row["EVALUATION"] == 'none') and (row["sequence_name"] == sequence_name):
            exp_it = str(row["exp_it"]).zfill(5)
            # Check if trajectory file exists (either CSV or TXT)
            traj_csv = os.path.join(trajectories_path, f"{exp_it}_{TRAJECTORY_FILE_NAME}.csv")
            traj_txt = os.path.join(trajectories_path, f"{exp_it}_{TRAJECTORY_FILE_NAME}.txt")
            if os.path.exists(traj_csv) or os.path.exists(traj_txt):
                runs_to_evaluate.append(exp_it)

    print_msg(SCRIPT_LABEL, f"Evaluating '{evaluation_folder.replace(sequence_name, f"{dataset.dataset_color}{sequence_name}\033[0m")}'")
    if len(runs_to_evaluate) == 0:
        exp_log.to_csv(exp.log_csv, index=False)
        return
    
    # Evaluate runs
    zip_files = []
    for exp_it in tqdm(runs_to_evaluate):
        # Try CSV first, then TXT
        trajectory_file_csv = os.path.join(trajectories_path, f"{exp_it}_{TRAJECTORY_FILE_NAME}.csv")
        trajectory_file_txt = os.path.join(trajectories_path, f"{exp_it}_{TRAJECTORY_FILE_NAME}.txt")
        
        trajectory_file = trajectory_file_csv
        if not os.path.exists(trajectory_file_csv):
            # If CSV doesn't exist, try TXT and convert to CSV
            if os.path.exists(trajectory_file_txt):
                traj_df = read_trajectory_txt(trajectory_file_txt)
                if traj_df is not None and not traj_df.empty:
                    # Add column names if needed (TUM format: ts tx ty tz qx qy qz qw)
                    if len(traj_df.columns) >= 8:
                        traj_df.columns = ['ts', 'tx', 'ty', 'tz', 'qx', 'qy', 'qz', 'qw']
                    # Save as CSV with header
                    save_trajectory_csv(trajectory_file_csv, traj_df, header=True)
                    trajectory_file = trajectory_file_csv
                else:
                    exp_log.loc[(exp_log["exp_it"] == int(exp_it)) & (exp_log["sequence_name"] == sequence_name),"EVALUATION"] = 'failed'
                    tqdm.write(format_msg(ws(8), f"Trajectory file is empty: {trajectory_file_txt}", "error"))
                    continue
            else:
                exp_log.loc[(exp_log["exp_it"] == int(exp_it)) & (exp_log["sequence_name"] == sequence_name),"EVALUATION"] = 'failed'
                tqdm.write(format_msg(ws(8), f"Trajectory file not found: {trajectory_file_csv} or {trajectory_file_txt}", "error"))
                continue
        
        success = evo_metric('ate', groundtruth_csv, trajectory_file, evaluation_folder, 1.0 / dataset.rgb_hz)
        if success[0]:
            zip_files.append(os.path.join(evaluation_folder, f"{exp_it}_{TRAJECTORY_FILE_NAME}.zip"))
        else:
            exp_log.loc[(exp_log["exp_it"] == int(exp_it)) & (exp_log["sequence_name"] == sequence_name),"EVALUATION"] = 'failed'
            tqdm.write(format_msg(ws(8), f"{success[1]}", "error"))
    if len(zip_files) == 0:
        exp_log.to_csv(exp.log_csv, index=False)
        return   
    
    # Retrieve accuracies
    evo_get_accuracy(zip_files, accuracy_csv)

    # Final Checks
    if not os.path.exists(accuracy_csv):
        exp_log.to_csv(exp.log_csv, index=False)
        return
    accuracy = pd.read_csv(accuracy_csv)
    for evaluated_run in runs_to_evaluate:
        if exp_log.loc[(exp_log["exp_it"] == int(exp_it)) & (exp_log["sequence_name"] == sequence_name),"EVALUATION"].any() == 'failed':
            continue
        trajectory_file = f"{evaluated_run}_{TRAJECTORY_FILE_NAME}.txt"
        exists = (accuracy["traj_name"] == trajectory_file).any()
        if exists:
            run_mask = (exp_log["exp_it"] == int(evaluated_run)) & (exp_log["sequence_name"] == sequence_name)
            exp_log.loc[run_mask, "EVALUATION"] = METRIC

            # Find number of frames in the sequence
            rgb_exp_csv = os.path.join(trajectories_path, f"rgb_exp.csv")
            with open(rgb_exp_csv, "r") as file:
                num_frames = sum(1 for _ in file)
            accuracy.loc[accuracy["traj_name"] == trajectory_file,"num_frames"] = num_frames
            exp_log.loc[run_mask, "num_frames"] = num_frames

            # Find number of tracked frames
            trajectory_file_txt = os.path.join(evaluation_folder, trajectory_file)
            if not os.path.exists(trajectory_file_txt):
                exp_log.loc[(exp_log["exp_it"] == int(evaluated_run)) & (exp_log["sequence_name"] == sequence_name),"EVALUATION"] = 'failed'
                continue
            with open(trajectory_file_txt, "r") as file:
                num_tracked_frames = sum(1 for _ in file)
            accuracy.loc[accuracy["traj_name"] == trajectory_file,"num_tracked_frames"] = num_tracked_frames    
            exp_log.loc[run_mask, "num_tracked_frames"] = num_tracked_frames

            # Find number of evaluated frames
            trajectory_file_tum = os.path.join(trajectories_path,VSLAM_LAB_EVALUATION_FOLDER, trajectory_file.replace(".txt", ".tum"))
            if not os.path.exists(trajectory_file_tum):
                exp_log.loc[(exp_log["exp_it"] == int(evaluated_run)) & (exp_log["sequence_name"] == sequence_name),"EVALUATION"] = 'failed'
                continue
            with open(trajectory_file_tum, "r") as file:
                num_evaluated_frames = sum(1 for _ in file) - 1
            accuracy.loc[accuracy["traj_name"] == trajectory_file,"num_evaluated_frames"] = num_evaluated_frames   
            exp_log.loc[run_mask, "num_evaluated_frames"] = num_evaluated_frames 
        else:
            exp_log.loc[(exp_log["exp_it"] == int(evaluated_run)) & (exp_log["sequence_name"] == sequence_name),"EVALUATION"] = 'failed'

    exp_log.to_csv(exp.log_csv, index=False)
    accuracy.to_csv(accuracy_csv, index=False)

